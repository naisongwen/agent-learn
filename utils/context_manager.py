"""
ä¸Šä¸‹æ–‡ç®¡ç†å™¨
å¤„ç†å¯¹è¯å†å²ã€ä»¤ç‰Œè®¡æ•°å’Œä¸Šä¸‹æ–‡å‹ç¼©
"""

import json
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

logger = logging.getLogger(__name__)

@dataclass
class Message:
    """æ¶ˆæ¯æ•°æ®ç±»"""
    role: str
    content: str
    timestamp: datetime = None
    task_id: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "role": self.role,
            "content": self.content,
            "timestamp": self.timestamp.isoformat(),
            "task_id": self.task_id,
            "metadata": self.metadata or {}
        }

class ContextManager:
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, max_tokens: int = 4000, compression_threshold: float = 0.8):
        self.max_tokens = max_tokens
        self.compression_threshold = compression_threshold
        self.messages: List[Message] = []
        self.token_count = 0
        self.compression_count = 0
        
    def add_message(self, message: Message) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡"""
        self.messages.append(message)
        self.token_count += self._count_tokens(message)
        logger.debug(f"æ·»åŠ æ¶ˆæ¯: {message.role}, å½“å‰ä»¤ç‰Œæ•°: {self.token_count}")
    
    def add_message_dict(self, message_dict: Dict[str, Any]) -> None:
        """æ·»åŠ å­—å…¸æ ¼å¼çš„æ¶ˆæ¯"""
        message = Message(
            role=message_dict["role"],
            content=message_dict["content"],
            task_id=message_dict.get("task_id"),
            metadata=message_dict.get("metadata")
        )
        self.add_message(message)
    
    def should_compress(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©ä¸Šä¸‹æ–‡"""
        threshold_tokens = int(self.max_tokens * self.compression_threshold)
        needs_compression = self.token_count > threshold_tokens
        if needs_compression:
            logger.info(f"è§¦å‘å‹ç¼©: {self.token_count} > {threshold_tokens} tokens")
        return needs_compression
    
    def compress_context(self) -> Dict[str, Any]:
        """æ‰§è¡Œä¸Šä¸‹æ–‡å‹ç¼©"""
        if not self.messages:
            return {"compressed": False, "reason": "æ— æ¶ˆæ¯å¯å‹ç¼©"}
        
        logger.info("å¼€å§‹æ‰§è¡Œä¸Šä¸‹æ–‡å‹ç¼©...")
        
        # ä¿ç•™ç­–ç•¥ï¼šç”¨æˆ·æ¶ˆæ¯ + æœ€è¿‘Næ¡éç”¨æˆ·æ¶ˆæ¯
        user_messages = [msg for msg in self.messages if msg.role == "user"]
        non_user_messages = [msg for msg in self.messages if msg.role != "user"]
        
        # ä¿ç•™æœ€è¿‘çš„5æ¡éç”¨æˆ·æ¶ˆæ¯
        recent_non_user = non_user_messages[-5:] if len(non_user_messages) > 5 else non_user_messages
        
        # é‡æ–°ç»„åˆæ¶ˆæ¯åˆ—è¡¨
        compressed_messages = user_messages + recent_non_user
        
        # æŒ‰æ—¶é—´æ’åºä¿æŒé¡ºåº
        compressed_messages.sort(key=lambda x: x.timestamp)
        
        # è®¡ç®—å‹ç¼©å‰åçš„ä»¤ç‰Œæ•°
        old_token_count = self.token_count
        new_token_count = sum(self._count_tokens(msg) for msg in compressed_messages)
        
        # æ›´æ–°çŠ¶æ€
        self.messages = compressed_messages
        self.token_count = new_token_count
        self.compression_count += 1
        
        compression_stats = {
            "compressed": True,
            "original_tokens": old_token_count,
            "compressed_tokens": new_token_count,
            "compression_ratio": round((old_token_count - new_token_count) / old_token_count, 3),
            "messages_removed": len(non_user_messages) - len(recent_non_user),
            "compression_count": self.compression_count
        }
        
        logger.info(f"å‹ç¼©å®Œæˆ: {old_token_count} â†’ {new_token_count} tokens "
                   f"(å‹ç¼©ç‡: {compression_stats['compression_ratio']*100:.1f}%)")
        
        return compression_stats
    
    def get_context_stats(self) -> Dict[str, Any]:
        """è·å–ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯"""
        role_counts = {}
        task_counts = {}
        
        for msg in self.messages:
            role_counts[msg.role] = role_counts.get(msg.role, 0) + 1
            if msg.task_id:
                task_counts[msg.task_id] = task_counts.get(msg.task_id, 0) + 1
        
        return {
            "total_messages": len(self.messages),
            "total_tokens": self.token_count,
            "max_tokens": self.max_tokens,
            "compression_threshold": self.compression_threshold,
            "compression_count": self.compression_count,
            "role_distribution": role_counts,
            "task_distribution": task_counts,
            "utilization_rate": round(self.token_count / self.max_tokens, 3)
        }
    
    def get_recent_messages(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„æ¶ˆæ¯"""
        recent = self.messages[-limit:] if len(self.messages) > limit else self.messages
        return [msg.to_dict() for msg in recent]
    
    def clear_context(self) -> None:
        """æ¸…ç©ºä¸Šä¸‹æ–‡"""
        self.messages.clear()
        self.token_count = 0
        logger.info("ä¸Šä¸‹æ–‡å·²æ¸…ç©º")
    
    def _count_tokens(self, message: Message) -> int:
        """ä¼°ç®—æ¶ˆæ¯çš„ä»¤ç‰Œæ•°"""
        # ç®€åŒ–çš„ä»¤ç‰Œè®¡ç®—ï¼šæ¯ä¸ªå­—ç¬¦çº¦0.3ä¸ªtoken
        text_content = str(message.content)
        return int(len(text_content) * 0.3)
    
    def to_openai_format(self) -> List[Dict[str, Any]]:
        """è½¬æ¢ä¸º OpenAI API æ ¼å¼"""
        return [
            {
                "role": msg.role,
                "content": msg.content
            }
            for msg in self.messages
        ]

# ä¾¿æ·å‡½æ•°
def create_context_manager(max_tokens: int = 4000) -> ContextManager:
    """åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹"""
    return ContextManager(max_tokens=max_tokens)

def demo_context_management():
    """æ¼”ç¤ºä¸Šä¸‹æ–‡ç®¡ç†åŠŸèƒ½"""
    print("ğŸ¤– ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¼”ç¤º")
    print("=" * 40)
    
    # åˆ›å»ºç®¡ç†å™¨
    cm = ContextManager(max_tokens=1000, compression_threshold=0.7)
    
    # æ·»åŠ æµ‹è¯•æ¶ˆæ¯
    test_messages = [
        {"role": "user", "content": "åˆ†æé¡¹ç›®ä»£ç ç»“æ„"},
        {"role": "assistant", "content": "æ­£åœ¨åˆ†æ...", "task_id": "task_001"},
        {"role": "tool", "content": "å‘ç°3ä¸ªä¸»è¦æ¨¡å—", "task_id": "task_001"},
        {"role": "assistant", "content": "åˆ†æå®Œæˆï¼Œå»ºè®®å¦‚ä¸‹..."},
        {"role": "user", "content": "è¯·è¯¦ç»†è¯´æ˜ç¬¬ä¸€ä¸ªæ¨¡å—"},
        {"role": "assistant", "content": "ç¬¬ä¸€ä¸ªæ¨¡å—æ˜¯è®¤è¯ç³»ç»Ÿ..."},
        {"role": "user", "content": "å¸®æˆ‘é‡æ„è¿™ä¸ªæ¨¡å—"},
        {"role": "assistant", "content": "å¼€å§‹é‡æ„...", "task_id": "task_002"},
        {"role": "tool", "content": "é‡æ„å®Œæˆï¼Œæµ‹è¯•é€šè¿‡", "task_id": "task_002"},
        {"role": "assistant", "content": "é‡æ„å·²å®Œæˆï¼Œä¸»è¦æ”¹è¿›..."},
    ]
    
    print("ğŸ“¥ æ·»åŠ æµ‹è¯•æ¶ˆæ¯...")
    for i, msg_dict in enumerate(test_messages):
        cm.add_message_dict(msg_dict)
        print(f"  æ¶ˆæ¯ {i+1}: {msg_dict['role']} - {len(msg_dict['content'])} å­—ç¬¦")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = cm.get_context_stats()
    print(f"\nğŸ“Š ä¸Šä¸‹æ–‡ç»Ÿè®¡:")
    print(f"  æ€»æ¶ˆæ¯æ•°: {stats['total_messages']}")
    print(f"  æ€»ä»¤ç‰Œæ•°: {stats['total_tokens']}")
    print(f"  åˆ©ç”¨ç‡: {stats['utilization_rate']*100:.1f}%")
    print(f"  è§’è‰²åˆ†å¸ƒ: {stats['role_distribution']}")
    
    # æ£€æŸ¥å‹ç¼©éœ€æ±‚
    if cm.should_compress():
        compression_result = cm.compress_context()
        print(f"\nğŸ”„ å‹ç¼©ç»“æœ:")
        print(f"  å‹ç¼©å‰: {compression_result['original_tokens']} tokens")
        print(f"  å‹ç¼©å: {compression_result['compressed_tokens']} tokens")
        print(f"  å‹ç¼©ç‡: {compression_result['compression_ratio']*100:.1f}%")
    
    # æ˜¾ç¤ºæœ€è¿‘æ¶ˆæ¯
    print(f"\nğŸ“ æœ€è¿‘3æ¡æ¶ˆæ¯:")
    recent = cm.get_recent_messages(3)
    for msg in recent:
        print(f"  [{msg['role']}] {msg['content'][:50]}...")
    
    return cm

if __name__ == "__main__":
    demo_context_management()